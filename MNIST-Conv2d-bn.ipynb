{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv2d MNIST Model\n",
    "In this notebook we will create a model to predicts what letter is written in a 28x28 image based on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).  This is done via a convolutional Neural Network on the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Tensorflow & Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HyperParams\n",
    "learning_rate = 0.002\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# Input\n",
    "inputs = tf.placeholder(tf.float32, [None, 28, 28, 1], name='inputs')\n",
    "labels = tf.placeholder(tf.float32, [None, 10], name='labels')\n",
    "\n",
    "is_training = tf.placeholder(tf.bool, name='is_training')\n",
    "\n",
    "with tf.name_scope('Conv_1'):\n",
    "    # Conv 1\n",
    "    layer = tf.layers.conv2d(inputs, 16, 5, strides=2, padding='same', use_bias=False, activation=None)\n",
    "    # layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    # ?x14x14x16\n",
    "\n",
    "with tf.name_scope('Conv_2'):\n",
    "    # Conv 2\n",
    "    layer = tf.layers.conv2d(layer, 32, 5, strides=2, padding='same', use_bias=False, activation=None)\n",
    "    # layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    # ?x7x7x32\n",
    "\n",
    "    layer = tf.reshape(layer, (-1, 7*7*32))\n",
    "\n",
    "with tf.name_scope('Dense_1'):\n",
    "    # Fully Connected\n",
    "    layer = tf.layers.dense(layer, 64, use_bias=False, activation=None)\n",
    "    # layer = tf.layers.batch_normalization(layer, training=is_training)\n",
    "    layer = tf.nn.relu(layer)\n",
    "    # ?x64\n",
    "    \n",
    "with tf.name_scope('Logits'):\n",
    "    # Logits\n",
    "    logits = tf.layers.dense(layer, 10)\n",
    "    # ?x10\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    # Loss\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "\n",
    "with tf.name_scope('Optimizers'):\n",
    "    # Optimizer\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        train_opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "with tf.name_scope('Accuracy'):\n",
    "    # Accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_writer = tf.summary.FileWriter('./mnist-conv2d-bn-logs/1', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10... Batch Loss: 0.02586... Batch Accuracy: 0.95312... Valid Loss: 0.01788... Valid Accuracy: 0.97720\n",
      "Epoch  2/10... Batch Loss: 0.01115... Batch Accuracy: 0.98438... Valid Loss: 0.01169... Valid Accuracy: 0.98440\n",
      "Epoch  3/10... Batch Loss: 0.00418... Batch Accuracy: 1.00000... Valid Loss: 0.00924... Valid Accuracy: 0.98780\n",
      "Epoch  4/10... Batch Loss: 0.00507... Batch Accuracy: 0.98438... Valid Loss: 0.00844... Valid Accuracy: 0.99000\n",
      "Epoch  5/10... Batch Loss: 0.01592... Batch Accuracy: 0.96875... Valid Loss: 0.00905... Valid Accuracy: 0.98820\n",
      "Epoch  6/10... Batch Loss: 0.00454... Batch Accuracy: 0.98438... Valid Loss: 0.00879... Valid Accuracy: 0.98920\n",
      "Epoch  7/10... Batch Loss: 0.00079... Batch Accuracy: 1.00000... Valid Loss: 0.00832... Valid Accuracy: 0.99020\n",
      "Epoch  8/10... Batch Loss: 0.00007... Batch Accuracy: 1.00000... Valid Loss: 0.00957... Valid Accuracy: 0.99000\n",
      "Epoch  9/10... Batch Loss: 0.00179... Batch Accuracy: 1.00000... Valid Loss: 0.00990... Valid Accuracy: 0.98920\n",
      "Epoch 10/10... Batch Loss: 0.00005... Batch Accuracy: 1.00000... Valid Loss: 0.00867... Valid Accuracy: 0.99120\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for ii in range(mnist.train.num_examples//batch_size):\n",
    "            batch_inputs, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            sess.run(train_opt, feed_dict={\n",
    "                inputs: batch_inputs, \n",
    "                labels: batch_labels, \n",
    "                is_training: True\n",
    "            })\n",
    "        \n",
    "        b_loss, b_accuracy = sess.run([loss, accuracy], feed_dict={\n",
    "            inputs: batch_inputs, \n",
    "            labels: batch_labels, \n",
    "            is_training: False\n",
    "        })\n",
    "        \n",
    "        v_loss, v_accuracy = sess.run([loss, accuracy], feed_dict={\n",
    "            inputs: mnist.validation.images, \n",
    "            labels: mnist.validation.labels, \n",
    "            is_training: False\n",
    "        })\n",
    "        \n",
    "        print(\n",
    "            \"Epoch {:2d}/{}...\".format(e+1, epochs),\n",
    "            \"Batch Loss: {:>3.5f}...\".format(b_loss),\n",
    "            \"Batch Accuracy: {:>3.5f}...\".format(b_accuracy),\n",
    "            \"Valid Loss: {:>3.5f}...\".format(v_loss),\n",
    "            \"Valid Accuracy: {:>3.5f}\".format(v_accuracy)\n",
    "        )\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
