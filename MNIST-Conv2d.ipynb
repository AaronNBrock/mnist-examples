{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e98280a2-2321-4290-9f94-77ee5d39e2f7"
    }
   },
   "source": [
    "# Simple MNIST Model\n",
    "\n",
    "In this notebook we will create a simple model to predicts what letter is written in a 28x28 image based on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).  This is done via a two fully connected layer Neural Network on a flattened version of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "81f31bb2-0012-405d-acb2-5fc4ceeb463d"
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "ea336b2d-4ba4-4054-92ad-bf420b56709a"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Mnist Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image.reshape((28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [0 0 0 0 0 0 0 1 0 0]\n",
      "Argmax: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13a532d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = random.randint(0, len(mnist.train.images))\n",
    "\n",
    "image = mnist.train.images[index]\n",
    "label = mnist.train.labels[index]\n",
    "\n",
    "print('Label: {}\\nArgmax: {}'.format(label.astype(int), np.argmax(label)))\n",
    "\n",
    "show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4829090c-07c5-4964-a84a-701a5b89f294"
    }
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset graph\n",
    "tf.reset_default_graph()\n",
    "# Set reuse to AUTO_REUSE, this allows you to run tf.get_variable() more than once.\n",
    "tf.get_variable_scope()._reuse = tf.AUTO_REUSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "learning_rate = 0.01\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "# Epochs\n",
    "epochs = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "91eb9701-a56a-4695-ab94-8d9eb2c98206"
    }
   },
   "source": [
    "#### Model Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbpresent": {
     "id": "9229f34c-08e4-4285-b2f0-750cdaa195b0"
    }
   },
   "outputs": [],
   "source": [
    "# Input Images\n",
    "features = tf.placeholder(tf.float32, [None, 28, 28, 1], name='features')\n",
    "\n",
    "# True Values\n",
    "labels = tf.placeholder(tf.float32, [None, 10], name='labels')\n",
    "\n",
    "# Keep Probability\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a12af5e5-d37f-40b3-83e3-4bca21ab0eca"
    }
   },
   "source": [
    "#### Layer 1: Convolution/Max Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbpresent": {
     "id": "6688439c-cd74-4d5f-9f54-ac8eeb169518"
    }
   },
   "outputs": [],
   "source": [
    "# Shape = 28x28x1\n",
    "\n",
    "# Weights\n",
    "W_1 = tf.get_variable('W_1', shape=[5, 5, 1, 32], initializer=tf.truncated_normal_initializer)\n",
    "# Bias\n",
    "b_1 = tf.get_variable('b_1', shape=[32], initializer=tf.zeros_initializer)\n",
    "# Create Layer\n",
    "layer_1 = tf.nn.conv2d(features, W_1, strides=[1, 1, 1, 1], padding='SAME') + b_1\n",
    "# Activate\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "# Shape = 28x28x32\n",
    "\n",
    "# Max Pool\n",
    "layer_1 = tf.nn.max_pool(layer_1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Shape = 14x14x32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 2: Convolution/Max Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape = 14x14x32\n",
    "\n",
    "# Weights\n",
    "W_2 = tf.get_variable('W_2', shape=[5, 5, 32, 64], initializer=tf.truncated_normal_initializer)\n",
    "# Bias\n",
    "b_2 = tf.get_variable('b_2', shape=[64], initializer=tf.zeros_initializer)\n",
    "# Create Layer\n",
    "layer_2 = tf.nn.conv2d(layer_1, W_2, strides=[1, 1, 1, 1], padding='SAME') + b_2\n",
    "# Activate\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "# Shape = 14x14x64\n",
    "\n",
    "# Max Pool\n",
    "layer_2 = tf.nn.max_pool(layer_2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "# Shape = 7x7x64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape = 7x7x64\n",
    "\n",
    "flattened = tf.reshape(layer_2, shape=[-1, 7*7*64])\n",
    "\n",
    "# Shape = (7*7*64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 3: Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "W_3 = tf.get_variable('W_3', shape=[7*7*64, 1024], initializer=tf.truncated_normal_initializer)\n",
    "# Bias\n",
    "b_3 = tf.get_variable('b_3', shape=[1024], initializer=tf.zeros_initializer)\n",
    "# Create Layer\n",
    "layer_3 = tf.matmul(flattened, W_3) + b_3\n",
    "# Activate\n",
    "layer_3 = tf.nn.relu(layer_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 4: Fully Connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "W_4 = tf.get_variable('W_4', shape=[1024, 10], initializer=tf.truncated_normal_initializer)\n",
    "# Bias\n",
    "b_4 = tf.get_variable('b_4', shape=[10], initializer=tf.zeros_initializer)\n",
    "# Create Layer\n",
    "layer_4 = tf.matmul(layer_3, W_4) + b_4\n",
    "\n",
    "# No Activation on last layer, since that's covered by Softmax in the loss function.\n",
    "logits = layer_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbpresent": {
     "id": "77576169-b0c3-4b16-87fb-1d132a2d715e"
    }
   },
   "outputs": [],
   "source": [
    "# Cross entropy\n",
    "cross_entropys = tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits)\n",
    "\n",
    "average_cross_entropy = tf.reduce_mean(cross_entropys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "# Training Step\n",
    "train_step = optimizer.minimize(average_cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(labels, 1), tf.argmax(logits, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "96345023-61d9-4ed4-bd92-0b2558ae6b6d"
    }
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = './checkpoints/conv2d.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   0 Train Accuracy: 0.109\n",
      "Epoch: 100 Train Accuracy: 0.883\n",
      "Epoch: 200 Train Accuracy: 0.941\n",
      "Epoch: 300 Train Accuracy: 0.973\n",
      "Epoch: 400 Train Accuracy: 0.980\n",
      "Epoch: 500 Train Accuracy: 0.973\n",
      "Test Accuracy: 0.959\n"
     ]
    }
   ],
   "source": [
    "print_every = 100\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs+1):\n",
    "        \n",
    "        batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, acc = sess.run([train_step, accuracy], feed_dict={\n",
    "            features: batch_features,\n",
    "            labels: batch_labels\n",
    "        })\n",
    "        \n",
    "        if e % print_every == 0:\n",
    "            print('Epoch:{:4} Train Accuracy: {:.3f}'.format(e, acc))\n",
    "    \n",
    "    \n",
    "    acc = sess.run(accuracy, feed_dict={\n",
    "        features: mnist.test.images,\n",
    "        labels: mnist.test.labels\n",
    "    })\n",
    "    print('Test Accuracy: {:.3f}'.format(acc))\n",
    "    \n",
    "    saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "063c912e-a9b6-4142-865b-6eb4c246a65e"
    }
   },
   "source": [
    "## Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "edca66a2-2ab3-4b41-9d7b-12f43d8e6c6a"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoints/conv2d.ckpt\n",
      "\n",
      "Label: [0 0 0 0 0 0 0 0 1 0]\n",
      "Argmax: 8\n",
      "\n",
      "Logit: [ -313   743  -520   318  -346    42 -1264  -209  2736 -1078]\n",
      "Argmax: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADYBJREFUeJzt3X+o1fUdx/HXuztnlIZlZbd254/IaBRr6yKDRrRmo63ANAsjwjHpRhRMGLIowmQMbO5n/0h3dPEO5p1itSRGKbXWBiPymv1Qp4m4zTQtDWxErPK9P+7XcbP7/XyP53y/53v0/XyAnHO+7/M53zcHX/f7/Z7v95yPubsAxHNa3Q0AqAfhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1BfauTIz43JCoGLubo08r6Utv5ndYGY7zGyXmd3fymsBaC9r9tp+M+uStFPS9ZL2SnpF0u3uvi0xhi0/ULF2bPlnSdrl7rvd/b+S/iBpTguvB6CNWgn/RZL+Perx3mzZZ5hZn5ltMrNNLawLQMla+cBvrF2Lz+3Wu3u/pH6J3X6gk7Sy5d8rqWfU4y9J2tdaOwDapZXwvyLpEjObbmZflLRA0vpy2gJQtaZ3+939EzO7T9JzkrokDbj71tI6A1Cppk/1NbUyjvmByrXlIh8AJy/CDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Jq6xTd6DyTJ09O1leuXJms33jjjcn6unXrcmuPPvpocuzw8HCyjtaw5QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoFqapdfM9kj6QNKnkj5x996C5zNLb5vNnj07WV+zZk2yPmnSpGR9586dyXp3d3du7fTTT0+O7enpSdbffffdZD2qRmfpLeMin2+5+3slvA6ANmK3Hwiq1fC7pA1mNmxmfWU0BKA9Wt3tv9rd95nZ+ZI2mtk/3P2l0U/I/ijwhwHoMC1t+d19X3Z7UNJTkmaN8Zx+d+8t+jAQQHs1HX4zO9PMJh67L+k7kt4sqzEA1Wplt3+KpKfM7NjrrHb3Z0vpCkDlmg6/u++W9NUSe0GTurq6cmsPPvhgcuwZZ5yRrC9atChZL7pOIHWef9euXcmxp53Gyagq8e4CQRF+ICjCDwRF+IGgCD8QFOEHguKnu08BCxYsyK1dc801ybEbN25M1letWtVMS/+3e/fupsded911yfrQ0FDTrw22/EBYhB8IivADQRF+ICjCDwRF+IGgCD8QFOf5T3HZ7y00XS8yfvz4ZH3ZsmUtvT6qw5YfCIrwA0ERfiAowg8ERfiBoAg/EBThB4LiPP8p4Nln86dLOHLkSHLshAkTkvVx48Yl6/Pnz0/WlyxZkqynvPDCC02PRTG2/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVOF5fjMbkHSTpIPufnm27BxJayRNk7RH0m3u/n51bSLl0KFDubWBgYHk2MWLFyfrK1asSNbvuuuuZH14eDi3dsUVVyTHHj16NFlHaxrZ8q+SdMNxy+6X9Ly7XyLp+ewxgJNIYfjd/SVJh49bPEfSYHZ/UNLNJfcFoGLNHvNPcff9kpTdnl9eSwDaofJr+82sT1Jf1esBcGKa3fIfMLNuScpuD+Y90d373b3X3XubXBeACjQb/vWSFmb3F0p6upx2ALRLYfjNbEjS3yVdamZ7zWyRpOWSrjeztyRdnz0GcBIxd2/fyszatzJIku68885kfXBwMFkv+v/x/vvpyzsuvfTS3NrUqVOTYzdv3pysY2zu3tBkDFzhBwRF+IGgCD8QFOEHgiL8QFCEHwiKU33Btfq12XfeeSdZv/DCC1t6fZw4TvUBSCL8QFCEHwiK8ANBEX4gKMIPBEX4gaCYovsUd9VVV7U0vug6kPPOOy9ZX7ZsWW5t6dKlTfWEcrDlB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg+D7/KaCrqyu39sgjjyTHzps3L1m/5557kvXHHnssWe/p6cmtzZo1Kzk2Nb038vF9fgBJhB8IivADQRF+ICjCDwRF+IGgCD8QVOF5fjMbkHSTpIPufnm27GFJd0l6N3vaA+7+p8KVcZ6/EhdccEFu7e23306O7e/vT9aLzvPPnTs3WV+3bl1u7fDhw8mxM2fOTNaLpgePqszz/Ksk3TDG8l+5+5XZv8LgA+gsheF395ckpf9EAzjptHLMf5+ZvW5mA2Z2dmkdAWiLZsO/UtLFkq6UtF/SL/KeaGZ9ZrbJzDY1uS4AFWgq/O5+wN0/dfejkn4rKfcbGu7e7+697t7bbJMAytdU+M2se9TDuZLeLKcdAO1S+NPdZjYk6VpJ55rZXklLJV1rZldKckl7JN1dYY8AKlAYfne/fYzFj1fQC5q0ZMmS3JpZ+pTvihUrWlr3iy++mKynzuVPnjw5OXbq1KnJOuf5W8MVfkBQhB8IivADQRF+ICjCDwRF+IGg+OnuU8Crr76aW9uxY0dy7IIFC8pu5zPmz5+fW1u7dm1y7NDQULJ+xx13NNXTqY6f7gaQRPiBoAg/EBThB4Ii/EBQhB8IivADQRV+pRcnt48++qjW9ad+urvIZZddVmInOB5bfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivP8J4EZM2Yk69OnT8+tvfbaa2W3c0Jmz55d6/qRjy0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVeJ7fzHok/U7SBZKOSup399+Y2TmS1kiaJmmPpNvcnTmTKzBx4sRk/ayzzsqtFU3R3arx48cn6319fbm1qqcPR1ojW/5PJP3I3S+T9A1J95rZVyTdL+l5d79E0vPZYwAnicLwu/t+d9+c3f9A0nZJF0maI2kwe9qgpJurahJA+U7omN/Mpkn6mqSXJU1x9/3SyB8ISeeX3RyA6jR8bb+ZTZD0hKTF7n6k0WNJM+uTlH/gB6AWDW35zWycRoL/e3d/Mlt8wMy6s3q3pINjjXX3fnfvdffeMhoGUI7C8NvIJv5xSdvd/ZejSuslLczuL5T0dPntAahKI7v9V0u6U9IbZrYlW/aApOWS1prZIkn/knRrNS1i27ZtyfrWrVtza5MmTSq7nc9ITcEtSbfccktu7ciRI8mxGzZsaKonNKYw/O7+N0l5B/jfLrcdAO3CFX5AUIQfCIrwA0ERfiAowg8ERfiBoPjp7pPAxx9/nKyvXr06t/bQQw8lx27ZsiVZd/dkfebMmcn6hx9+mFubN29ecuyhQ4eSdbSGLT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBGVF53FLXZlZ+1YGScXft1++fHmynpr+W0qfx5fS5/I3btyYHIvmuHtDv7HHlh8IivADQRF+ICjCDwRF+IGgCD8QFOEHguI8P3CK4Tw/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiqMPxm1mNmfzaz7Wa21cx+mC1/2MzeNrMt2b/vVd8ugLIUXuRjZt2Sut19s5lNlDQs6WZJt0n6j7v/vOGVcZEPULlGL/IpnLHH3fdL2p/d/8DMtku6qLX2ANTthI75zWyapK9JejlbdJ+ZvW5mA2Z2ds6YPjPbZGabWuoUQKkavrbfzCZI+oukn7r7k2Y2RdJ7klzSTzRyaPCDgtdgtx+oWKO7/Q2F38zGSXpG0nPu/ssx6tMkPePulxe8DuEHKlbaF3vMzCQ9Lmn76OBnHwQeM1fSmyfaJID6NPJp/zcl/VXSG5KOZosfkHS7pCs1stu/R9Ld2YeDqddiyw9UrNTd/rIQfqB6fJ8fQBLhB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqMIf8CzZe5L+OerxudmyTtSpvXVqXxK9NavM3qY2+sS2fp//cys32+TuvbU1kNCpvXVqXxK9Nauu3tjtB4Ii/EBQdYe/v+b1p3Rqb53al0Rvzaqlt1qP+QHUp+4tP4Ca1BJ+M7vBzHaY2S4zu7+OHvKY2R4zeyObebjWKcayadAOmtmbo5adY2Ybzeyt7HbMadJq6q0jZm5OzCxd63vXaTNet32338y6JO2UdL2kvZJekXS7u29rayM5zGyPpF53r/2csJldI+k/kn53bDYkM/uZpMPuvjz7w3m2u/+4Q3p7WCc4c3NFveXNLP191fjelTnjdRnq2PLPkrTL3Xe7+38l/UHSnBr66Hju/pKkw8ctniNpMLs/qJH/PG2X01tHcPf97r45u/+BpGMzS9f63iX6qkUd4b9I0r9HPd6rzpry2yVtMLNhM+uru5kxTDk2M1J2e37N/RyvcObmdjpuZumOee+amfG6bHWEf6zZRDrplMPV7v51Sd+VdG+2e4vGrJR0sUamcdsv6Rd1NpPNLP2EpMXufqTOXkYbo69a3rc6wr9XUs+ox1+StK+GPsbk7vuy24OSntLIYUonOXBsktTs9mDN/fyfux9w90/d/aik36rG9y6bWfoJSb939yezxbW/d2P1Vdf7Vkf4X5F0iZlNN7MvSlogaX0NfXyOmZ2ZfRAjMztT0nfUebMPr5e0MLu/UNLTNfbyGZ0yc3PezNKq+b3rtBmva7nIJzuV8WtJXZIG3P2nbW9iDGY2QyNbe2nkG4+r6+zNzIYkXauRb30dkLRU0h8lrZX0ZUn/knSru7f9g7ec3q7VCc7cXFFveTNLv6wa37syZ7wupR+u8ANi4go/ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANB/Q+S8P/UTOUUDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13a28d4a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_path)\n",
    "    \n",
    "    index = random.randint(0, len(mnist.train.images))\n",
    "    image = mnist.train.images[index]\n",
    "    label = mnist.train.labels[index]\n",
    "    \n",
    "    logit = sess.run(logits, feed_dict={\n",
    "        features: [image],\n",
    "        labels: [label]\n",
    "    })[0]\n",
    "    \n",
    "    # This is just to make the print statement nicer\n",
    "    label = label.astype(int)\n",
    "    logit = logit.astype(int)\n",
    "\n",
    "    print('\\nLabel: {}\\nArgmax: {}\\n\\nLogit: {}\\nArgmax: {}'.format(label, np.argmax(label), logit, np.argmax(logit)))\n",
    "    \n",
    "    show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
